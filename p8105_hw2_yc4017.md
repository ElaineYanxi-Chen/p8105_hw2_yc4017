p8105_hw2_yc4017
================

## Packages

First we load the packages necessary to knit this document.

``` r
library(tidyverse)
library(readxl)
```

# Problem 1: NYC Transit

-   We first read in the csv file and converted the column types for
    route8 to route 11 from double to characters to be consistent with
    the rest of the route variables.

-   Retain line, station, name, station latitute/longtitude, routes
    served, entry, vending, entrance type, and ADA compliance

-   Convert the entry variable from character to a logical variable

``` r
nyc_transit = read_csv("data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv",
                       col_types = cols(Route8 = "c", Route9 = "c", Route10 = "c", Route11 = "c")) %>% 
  janitor::clean_names() %>% 
  select(line:ada, -c(exit_only, staffing, staff_hours)) %>% 
  mutate(entry = if_else(entry == "YES", TRUE, FALSE))
```

trans_ent = read_csv(
“data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv”, col_types = )

Now we describe the characteristics of this nyc_transit dataset:

-   This datasets includes 19 variables for 1868 observations, however,
    there seems to some repeating observations in this dataset.

-   The dataset contains variables such as the subway line, station
    names, the station location expressed in latitude and longitude.

-   The dataset was first imported as a csv file, before the names were
    cleaned using the `janitor` package so that all variables and
    observations follow the snake case convention. We then selected only
    the variables of interest, before mutating the entry variable from a
    character variable with `YES` or `NO` responses to a logical
    variable with `TRUE` or `FALSE` responses.

-   The data is not tidy since there is quite a bit of repeat with
    routes served.

Next, we will use the following code chunks to answer some questions
about the dataset.

``` r
nyc_transit_dist = nyc_transit %>% 
  distinct(line, station_name)
```

-   There are 465 distinct stations in NYC subway.

``` r
nyc_transit_ada = nyc_transit %>% 
  filter(ada == TRUE) %>% 
  distinct(line, station_name) 
```

-   There are 84 stations that are ADA compliant.

``` r
nyc_transit_ent = nyc_transit %>% 
  filter(vending == "NO") %>% 
  pull(entry) %>% 
  mean
```

-   The proportion of station entrances/exits without vending allow
    entrance is 37.7%.

Finally, we reformat data so that the route number and route name are
distinct variables.

``` r
nyc_transit_a = nyc_transit %>% 
  pivot_longer(
    route1:route11,
    names_to = "route_number",
    values_to = "route"
  ) %>% 
  filter(route == "A") %>% 
  distinct(line, station_name)
```

There are 60 distinct stations that serve the A train.

``` r
nyc_transit_a_ada = nyc_transit %>% 
  pivot_longer(
    route1:route11,
    names_to = "route_number",
    values_to = "route"
  ) %>% 
  filter(route == "A", ada == TRUE) %>% 
  distinct(line, station_name)
```

There are 17 distinct stations that serve the A train and are ADA
compliant.

# Problem 2: Mr. Trash Wheel

We will first read the excel sheet Mr. Trash Wheel from the Excel file
and clean it.

``` r
mr_trash = read_excel("data/Trash Wheel Collection Data.xlsx", sheet = "Mr. Trash Wheel", range = "A2:N550") %>% 
  janitor::clean_names() %>% 
  drop_na(dumpster) %>% 
  mutate(sports_balls = as.integer(round(sports_balls, 0)))
```

We will then use a similar process to import, clean, and organize the
data for Professor Trash Wheel.

``` r
prof_trash = read_excel("data/Trash Wheel Collection Data.xlsx", sheet = "Professor Trash Wheel", range = "A2:M97") %>% 
  janitor::clean_names() %>% 
  drop_na(dumpster) 
```

Now we will assign an additional variable to keep track of which Trash
Wheel is which, then combine the two datasets.

``` r
mr_trash = mr_trash %>% mutate(trash_wheel = "mr")

prof_trash = prof_trash %>% mutate(trash_wheel = "prof",
                      year = as.character(year))

joint_trash = full_join(mr_trash, prof_trash)
```

    ## Joining, by = c("dumpster", "month", "year", "date", "weight_tons",
    ## "volume_cubic_yards", "plastic_bottles", "polystyrene", "cigarette_butts",
    ## "glass_bottles", "grocery_bags", "chip_bags", "homes_powered", "trash_wheel")

``` r
# Use binding rows? need to check this 
```

Below we describe some key characteristics of this joint dataset.

-   There are 641 variables for 15 observations.

-   These observations include the time, amount, and the type of trash
    collected. In addition, the number of Maryland homes powered by the
    incinerated trash are also included in the dataset.

    -   The month, year, and specific data were used to describe the
        time when trash were collected.

    -   The amount of trash includes the weight in tons and the volume
        in cubic yards.

    -   The type of trash includes plastic bottle, polystyrene,
        cigarette butts, glass bottles, grocery bags, and chip bags from
        both Mr Trash Wheel and Professor Trash Wheel, and sports balls
        from Mr Trash Wheel.

The total weight of trash collected by Professor Trash Wheel can be
found with the following code:

``` r
joint_trash %>% filter(trash_wheel == "prof") %>% select(weight_tons) %>% sum
```

    ## [1] 190.12

The total weight is 190.12 tons.

The total number of sports balls collected by Mr. Trash Wheel in 2020
can be found by the following code:

``` r
joint_trash %>% filter(trash_wheel == "mr", year == "2020") %>% 
  select(sports_balls) %>% sum
```

    ## [1] 856

The total number of sports balls collected is 856.

# Problem 3: FiveThirtyEight

## Clean the data in pols-month.csv

``` r
pols_month = read_csv("data/fivethirtyeight_datasets/pols-month.csv") %>% 
  janitor::clean_names() %>% 
  separate(col = mon, into = c("year", "month", "day", sep = "-")) %>% 
  select(-c("-", "day")) %>% 
  mutate(month = month.name[as.numeric(month)]) %>% 
  pivot_longer(c(prez_gop, prez_dem), names_to = "president", names_prefix = "prez_") %>% 
  filter(value == "1")
```

    ## Warning: Expected 4 pieces. Missing pieces filled with `NA` in 822 rows [1, 2,
    ## 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, ...].

Note that there are 5 observations in this dataset with `prez_gop` == 2,
which according to the coding should only be in (1 == yes, 0 == no).
These 5 observations have been filtered out.

## Clean the data in snp.csv

``` r
snp = read_csv("data/fivethirtyeight_datasets/snp.csv") %>%
  janitor::clean_names() %>% 
  separate(col = date, into = c("year", "month", "day", sep = "/")) %>% 
  select(-"/") %>% 
  mutate(month = month.abb[as.numeric(month)]) %>% 
  arrange(year, month) %>% 
  select(year, month, everything())
```

    ## Warning: Expected 4 pieces. Missing pieces filled with `NA` in 787 rows [1, 2,
    ## 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, ...].

## Tidy the unemployment data

``` r
unemploy = read_csv("data/fivethirtyeight_datasets/unemployment.csv") %>%
  janitor::clean_names() %>% 
  pivot_longer(jan:dec, names_to = "month", values_to = "unemploy_perc")
```

Here we have to make sure the key variables take the same values. The
months are all spelled as lower cases in the `unemployment` dataset, but
the first letters are capitalized in the `pols_month` and `snp`
datasets.

## Join the three datasets
